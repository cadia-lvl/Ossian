## --------------------------------------
[DEFAULT]
## --------------------------------------

## The DEFAULT section just gives a few global variables -- this is designed to reduce the
## number of paths you have to change when modifying this config file.

##!!! Change the following line to the top level of your copy of the Ossian code:
OSSIAN: __INSERT_PATH_TO_OSSIAN_HERE__
LANGUAGE: __INSERT_LANGUAGE_HERE__
SPEAKER: __INSERT_SPEAKER_HERE__
RECIPE: __INSERT_RECIPE_HERE__

## This line should point to the language/data/recipe combination you are working on:
TOP: %(OSSIAN)s/train/%(LANGUAGE)s/speakers/%(SPEAKER)s/%(RECIPE)s/

## spot for putting things in training -- not the final stored model:
WORKDIR: %(TOP)s/dnn_training_ACOUST/
DATADIR: %(TOP)s


## --------------------------------------
[Paths]
## --------------------------------------

work: %(WORKDIR)s/
data: %(DATADIR)s/
plot: %(WORKDIR)s/plots
file_id_list: __INSERT_FILELIST_HERE__
log_config_file: %(OSSIAN)s/tools/merlin/egs/slt_arctic/s1/conf/logging_config.conf
log_file: %(WORKDIR)s/log/log.txt
log_path: %(WORKDIR)s/log/

## You won't need these -- just leave the placeholder paths here:
sptk     :   /this/path/does/not/exist
straight :   /this/path/does/not/exist
in_mgc_dir: %(DATADIR)s/
in_lf0_dir: %(DATADIR)s/
in_bap_dir: %(DATADIR)s/


## --------------------------------------
[Labels]
## --------------------------------------

question_file_name  : %(TOP)s/questions_dnn.hed.cont
silence_pattern: ['*-sil+*']
label_type: state_align
label_align: %(TOP)s/lab_dnn
add_frame_features: True
subphone_feats: full


## --------------------------------------
[Input-Output]
## --------------------------------------

## This says that we are predicting 5 state durations per example (letter/phone)
## model_output_type must be either "duration" or "acoustic"
## Input and output normalization is either "MVN" or "MINMAX"
## if lf0 is one of the acoustic featues, the output_features must have an additional 'vuv' key (voiced un-voiced)
output_features  : ['mgc', 'lf0', 'vuv', 'bap']
mgc_dim  : 60
bap_dim  : 5
lf0_dim  : 1
dmgc_dim : 180
dbap_dim : 15
dlf0_dim : 3
model_output_type: acoustic
out_norm: MVN
inp_norm: MVN
inp_file_ext: .lab_dnn
out_file_ext: .cmp
## lab_ext: .lab_dnn
## mgc_ext: .mgc
## bap_ext: .bap
## lf0_ext: .lf0


## --------------------------------------
[Waveform]
## --------------------------------------

## This won't be used -- but keep it here as a placeholder:
vocoder_type : WORLD
framelength : 2048


## --------------------------------------
[Architecture]
## --------------------------------------

## Adjust the number and size of hidden layers here:
hidden_layer_size  : [512, 512, 512, 512]
hidden_layer_type  : ['tanh', 'tanh', 'tanh', 'tanh']

## backend
backend    : keras

## RNN training considerations
sequential_training : False
stateful            : False
shuffle_data        : True
batch_size          : 256

# Hyperparameters (used)
training_epochs      : 6
l1_reg               : 0.0
l2_reg               : 0.0
optimizer            : adam
loss_function        : mse
stopping_patience    : 10
restore_best_weights : True
dropout_rate         : 0.3
warmup_epoch         : 1000
warmup_momentum      : 0
output_activation    : linear

# Hyperparameters (unused)
pretraining_epochs : 0
pretraining_lr     : 0
learning_rate      : 0.002
hidden_activation  : tanh
private_l2_reg     : 0.0

# How many gpus used in training
gpu_num            : 1

## --------------------------------------
[Data]
## --------------------------------------

## We need to divide the files available up into train/validation/test data. We don't need
## to do any testing, but set test_file_number to 1 to keep the tools happy. Split the remaining
## files between train and validation. Using about 5% or 10% of the data for validation is
## pretty standard. This is how you might divide up 28 files:
train_file_number: __INSERT_NUMBER_OF_TRAINING_FILES_HERE__
valid_file_number: __INSERT_NUMBER_OF_VALIDATION_FILES_HERE__
test_file_number : __INSERT_NUMBER_OF_TEST_FILES_HERE__
#buffer size of each block of data to
buffer_size: 100000


## --------------------------------------
[Utility]
## --------------------------------------

plot : True


## --------------------------------------
[Processes]
## --------------------------------------

## For use with Ossian, just keep the first 4 set to True -- we will generate speech later
## within Ossian itself. You can run each of the 4 steps individually if you like:
MAKELAB  : True
MAKECMP  : True
NORMDATA : True
TRAINDNN : True
TESTDNN  : False


